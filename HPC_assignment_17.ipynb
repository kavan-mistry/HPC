{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6Xz-QbP_Gc0"
   },
   "source": [
    "# HPC assignment 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OIVrIFmPLg5P",
    "outputId": "40c92924-3647-42b4-da10-61f100be72b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 16 07:06:05 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   40C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ym1IHRFLqOq"
   },
   "source": [
    "## 1. To print hello message on the screen using kernal function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kuY-YyhYLP-9",
    "outputId": "95472387-2e46-4942-bc54-f5ca55b937e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hello_one.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile hello_one.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "__global__ void cuda_hello_one() {\n",
    "    printf(\"Hello World from GPU !\\n\");\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    cuda_hello_one<<<1,4>>>();\n",
    "    cudaDeviceSynchronize(); // Make sure all GPU work is done before exiting\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DSCY4EAILTZ8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvcc' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!nvcc -o hello_one hello_one.cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XLUUZdxJLZQv",
    "outputId": "0df66078-4932-445c-c879-03e890a47c18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World from GPU with grid dimension (1, 1) and block dimension (1, 1)!\n"
     ]
    }
   ],
   "source": [
    "!./hello_1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyPc75yXL526"
   },
   "source": [
    "## 2. To add two vectors of size 100 and 20000 and analyze the performance comparison between cpu and gpu processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZScCWhmRQ5rB"
   },
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZcvJganBVAHV",
    "outputId": "c814ad05-edee-46f2-9734-de86afcf7d0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycuda\n",
      "  Downloading pycuda-2024.1.tar.gz (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting pytools>=2011.2 (from pycuda)\n",
      "  Downloading pytools-2024.1.1-py2.py3-none-any.whl (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.1/85.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
      "Collecting mako (from pycuda)\n",
      "  Downloading Mako-1.3.3-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.5)\n",
      "Building wheels for collected packages: pycuda\n",
      "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pycuda: filename=pycuda-2024.1-cp310-cp310-linux_x86_64.whl size=661204 sha256=51efb7c5582dd86e48b9404a05e0a366352406f4840bf4dc162fe9a89aa2ad1c\n",
      "  Stored in directory: /root/.cache/pip/wheels/12/34/d2/9a349255a4eca3a486d82c79d21e138ce2ccd90f414d9d72b8\n",
      "Successfully built pycuda\n",
      "Installing collected packages: pytools, mako, pycuda\n",
      "Successfully installed mako-1.3.3 pycuda-2024.1 pytools-2024.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pycuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CixF6vnyL4os"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2vegVoEzPO5e"
   },
   "outputs": [],
   "source": [
    "# CUDA kernel function to add two vectors\n",
    "cuda_kernel_code = \"\"\"\n",
    "__global__ void vector_add(float *a, float *b, float *c, int n) {\n",
    "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (i < n) {\n",
    "        c[i] = a[i] + b[i];\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g2UkVmumPO0g"
   },
   "outputs": [],
   "source": [
    "cuda_module = SourceModule(cuda_kernel_code)\n",
    "vector_add_cuda = cuda_module.get_function(\"vector_add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJnuci7QPOug"
   },
   "outputs": [],
   "source": [
    "def vector_add_gpu(a, b):\n",
    "    n = a.size\n",
    "\n",
    "    a_gpu = cuda.mem_alloc(a.nbytes)\n",
    "    b_gpu = cuda.mem_alloc(b.nbytes)\n",
    "    c_gpu = cuda.mem_alloc(b.nbytes)\n",
    "\n",
    "    cuda.memcpy_htod(a_gpu, a)\n",
    "    cuda.memcpy_htod(b_gpu, b)\n",
    "\n",
    "    block_dim = (256, 1, 1)\n",
    "    grid_dim = ((n + block_dim[0] - 1) // block_dim[0], 1)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    vector_add_cuda(a_gpu, b_gpu, c_gpu, np.int32(n), block=block_dim, grid=grid_dim)\n",
    "\n",
    "    cuda.Context.synchronize()\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    c = np.empty_like(a)\n",
    "    cuda.memcpy_dtoh(c, c_gpu)\n",
    "\n",
    "    return c, end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nOMGUEfRPOrp"
   },
   "outputs": [],
   "source": [
    "vector_size_1 = 100\n",
    "vector_size_2 = 20000\n",
    "a = np.random.randn(vector_size_2).astype(np.float32)\n",
    "b = np.random.randn(vector_size_2).astype(np.float32)\n",
    "\n",
    "result_gpu1, gpu_time1 = vector_add_gpu(a[:vector_size_1], b[:vector_size_1])\n",
    "result_gpu2, gpu_time2 = vector_add_gpu(a[:vector_size_2], b[:vector_size_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RPZ3W9TpPOpE",
    "outputId": "c7dca35a-ab21-49ff-f27a-4bdf7c23a0b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector addition of size 100 on GPU took 0.0007643699645996094 seconds.\n",
      "Vector addition of size 20000 on GPU took 6.818771362304688e-05 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(\"Vector addition of size\", vector_size_1, \"on GPU took\", gpu_time1, \"seconds.\")\n",
    "\n",
    "print(\"Vector addition of size\", vector_size_2, \"on GPU took\", gpu_time2, \"seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvEheCs9QnP6"
   },
   "source": [
    "### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nO6v1mvxQPAX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zo1Vg8WJQO8b"
   },
   "outputs": [],
   "source": [
    "def vector_add_cpu(a, b):\n",
    "    start_time = time.time()\n",
    "    result = a + b\n",
    "    end_time = time.time()\n",
    "    return result, end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ylRC8U3yQO5m"
   },
   "outputs": [],
   "source": [
    "vector_size_1 = 100\n",
    "vector_size_2 = 20000\n",
    "a = np.random.randn(vector_size_2).astype(np.float32)\n",
    "b = np.random.randn(vector_size_2).astype(np.float32)\n",
    "\n",
    "result_cpu1, cpu_time1 = vector_add_cpu(a[:vector_size_1], b[:vector_size_1])\n",
    "result_cpu2, cpu_time2 = vector_add_cpu(a[:vector_size_2], b[:vector_size_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qvyOvmPVREnC",
    "outputId": "5b372129-324c-431d-f347-050e7423be1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector addition of size 100 on CPU took 0.0 seconds.\n",
      "Vector addition of size 20000 on CPU took 0.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(\"Vector addition of size\", vector_size_1, \"on CPU took\", cpu_time1, \"seconds.\")\n",
    "print(\"Vector addition of size\", vector_size_2, \"on CPU took\", cpu_time2, \"seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjE0ERXeXL_W"
   },
   "source": [
    "* Vector addition of size 100 on GPU took 0.0007691383361816406 seconds.\n",
    "* Vector addition of size 20000 on GPU took 7.128715515136719e-05 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlFZnJPSMCNU"
   },
   "source": [
    "## 3. To multply two matrix of size 20 X 20 and 1024 X 1024 analyze the performance comparison between cpu and gpu processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktQT63sESAbG"
   },
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJV-oQtaMJjs"
   },
   "outputs": [],
   "source": [
    "def matrix_multiply_gpu(a, b):\n",
    "    cuda_code = \"\"\"\n",
    "    __global__ void matrix_multiply(float *a, float *b, float *c, int n) {\n",
    "        int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "        int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "        if (row < n && col < n) {\n",
    "            float sum = 0.0;\n",
    "            for (int i = 0; i < n; ++i) {\n",
    "                sum += a[row * n + i] * b[i * n + col];\n",
    "            }\n",
    "            c[row * n + col] = sum;\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    mod = SourceModule(cuda_code)\n",
    "\n",
    "    matrix_multiply_cuda = mod.get_function(\"matrix_multiply\")\n",
    "\n",
    "    a_gpu = cuda.mem_alloc(a.nbytes)\n",
    "    b_gpu = cuda.mem_alloc(b.nbytes)\n",
    "    c_gpu = cuda.mem_alloc(a.nbytes)\n",
    "\n",
    "    cuda.memcpy_htod(a_gpu, a)\n",
    "    cuda.memcpy_htod(b_gpu, b)\n",
    "\n",
    "    block_size = (16, 16, 1)\n",
    "    grid_size = ((a.shape[1] + block_size[0] - 1) // block_size[0], (a.shape[0] + block_size[1] - 1) // block_size[1], 1)\n",
    "\n",
    "    matrix_multiply_cuda(a_gpu, b_gpu, c_gpu, np.int32(a.shape[0]), block=block_size, grid=grid_size)\n",
    "\n",
    "    c = np.empty_like(a)\n",
    "    cuda.memcpy_dtoh(c, c_gpu)\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MH0PTY5uR93A"
   },
   "outputs": [],
   "source": [
    "def generate_random_matrix(rows, cols):\n",
    "    return np.random.rand(rows, cols).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ARcmhxX4R9hH"
   },
   "outputs": [],
   "source": [
    "def measure_time(matrix_size, func, *args):\n",
    "    start_time = time.time()\n",
    "    result = func(*args)\n",
    "    end_time = time.time()\n",
    "    return result, end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wYUVcf1TV3NU"
   },
   "outputs": [],
   "source": [
    "matrix_sizes = [(20, 20), (1024, 1024)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZhDhR0szV3CK",
    "outputId": "4f4362ab-4763-475e-8da2-349439534094"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matrix size: (20, 20)\n",
      "GPU time: 0.428407 seconds\n",
      "\n",
      "Matrix size: (1024, 1024)\n",
      "GPU time: 0.018636 seconds\n"
     ]
    }
   ],
   "source": [
    "for size in matrix_sizes:\n",
    "    print(f\"\\nMatrix size: {size}\")\n",
    "    a = generate_random_matrix(*size)\n",
    "    b = generate_random_matrix(*size)\n",
    "\n",
    "    gpu_result, gpu_time = measure_time(size, matrix_multiply_gpu, a, b)\n",
    "    print(f\"GPU time: {gpu_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1qyw1pBSImQ"
   },
   "source": [
    "### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iodrO8o3R9c8"
   },
   "outputs": [],
   "source": [
    "def matrix_multiply_cpu(a, b):\n",
    "    result = np.zeros((a.shape[0], b.shape[1]), dtype=np.float32)\n",
    "    for i in range(a.shape[0]):\n",
    "        for j in range(b.shape[1]):\n",
    "            for k in range(a.shape[1]):\n",
    "                result[i, j] += a[i, k] * b[k, j]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YBPrjBRTR9Z2"
   },
   "outputs": [],
   "source": [
    "def generate_random_matrix(rows, cols):\n",
    "    return np.random.rand(rows, cols).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2npE0fjiSSlR"
   },
   "outputs": [],
   "source": [
    "def measure_time(matrix_size, func, *args):\n",
    "    start_time = time.time()\n",
    "    result = func(*args)\n",
    "    end_time = time.time()\n",
    "    return result, end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nSreHNxRu7iT"
   },
   "outputs": [],
   "source": [
    "matrix_sizes = [(20, 20), (1024, 1024)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZHw0TVRu-Tg",
    "outputId": "f670cf12-1063-48bc-cadb-2d3687e26bfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matrix size: (20, 20)\n",
      "CPU time: 0.000000 seconds\n",
      "\n",
      "Matrix size: (1024, 1024)\n",
      "CPU time: 533.798448 seconds\n"
     ]
    }
   ],
   "source": [
    "for size in matrix_sizes:\n",
    "    print(f\"\\nMatrix size: {size}\")\n",
    "    a = generate_random_matrix(*size)\n",
    "    b = generate_random_matrix(*size)\n",
    "\n",
    "    # CPU matrix multiplication\n",
    "    cpu_result, cpu_time = measure_time(size, matrix_multiply_cpu, a, b)\n",
    "    print(f\"CPU time: {cpu_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "840b6ln5XRuy"
   },
   "source": [
    "\n",
    "* Matrix size: (20, 20)\n",
    "* GPU time: 0.703994 seconds\n",
    "\n",
    "* Matrix size: (1024, 1024)\n",
    "* GPU time: 0.014648 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOLoudChMMdC"
   },
   "source": [
    "## 4. To obtain CUDA device information and print the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ZHjK0EQMwA0",
    "outputId": "ee6096c7-07de-4a1f-b494-5deeb8aa3a6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CUDA devices: 1\n",
      "\n",
      "CUDA Device: 0\n",
      "  Name: Tesla T4\n",
      "  Compute Capability: (7, 5)\n",
      "  Total Memory: 14.74810791015625 GB\n",
      "  Max Threads per Block: 1024\n",
      "  Multiprocessor Count: 40\n",
      "  Clock Rate: 1.59 GHz\n"
     ]
    }
   ],
   "source": [
    "import pycuda.driver as cuda\n",
    "\n",
    "# Initialize PyCUDA\n",
    "cuda.init()\n",
    "\n",
    "num_devices = cuda.Device.count()\n",
    "\n",
    "print(\"Number of CUDA devices:\", num_devices)\n",
    "\n",
    "for i in range(num_devices):\n",
    "    device = cuda.Device(i)\n",
    "    print(\"\\nCUDA Device:\", i)\n",
    "    print(\"  Name:\", device.name())\n",
    "    print(\"  Compute Capability:\", device.compute_capability())\n",
    "    print(\"  Total Memory:\", device.total_memory() / (1024 ** 3), \"GB\")\n",
    "    print(\"  Max Threads per Block:\", device.max_threads_per_block)\n",
    "    print(\"  Multiprocessor Count:\", device.multiprocessor_count)\n",
    "    print(\"  Clock Rate:\", device.clock_rate / 1e6, \"GHz\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
